version: "3.9"

services:
  backend:
    build:
      context: ./backend
    container_name: backend_app
    environment:
      ENV: ${ENV}
      DB_HOST: postgres
      DB_PORT: ${DB_PORT}
      DB_USER: ${DB_USER}
      DB_PASSWORD: ${DB_PASSWORD}
      DB_NAME: ${DB_NAME}
      KAFKA_BROKER: kafka:9092
    ports:
      - "8080:8080"
    networks:
      - app_net
    profiles:
      - dev

  frontend:
    build:
      context: ./frontend
    container_name: frontend_app
    ports:
      - "3000:80"
    networks:
      - app_net
    profiles:
      - dev

  postgres:
    image: postgres:17
    container_name: dev_postgres
    environment:
      POSTGRES_HOST_AUTH_METHOD: trust
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: ${DB_NAME}
    volumes:
      - pgdata:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - app_net
    profiles:
      - dev

  kafka:
    image: bitnami/kafka:3.6.0
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      - KAFKA_ENABLE_KRAFT=yes
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka:9093
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_CFG_MESSAGE_MAX_BYTES=200000000
      - KAFKA_CFG_REPLICA_FETCH_MAX_BYTES=200000000
      - KAFKA_CREATE_TOPICS=app-logs:1:1
    volumes:
      - kafka_data:/bitnami/kafka
    networks:
      - app_net
    profiles:
      - dev

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms2g -Xmx2g
      - xpack.security.enabled=false
      - xpack.security.http.ssl.enabled=false
    ports:
      - "9200:9200"
    networks:
      - app_net
    profiles:
      - dev
  
  kafka-connect:
    image: confluentinc/cp-kafka-connect:7.5.0
    container_name: kafka_connect
    depends_on:
      - kafka
      - elasticsearch
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "kafka:9092"
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
      CONNECT_GROUP_ID: "connect-cluster"
      CONNECT_CONFIG_STORAGE_TOPIC: "connect-configs"
      CONNECT_OFFSET_STORAGE_TOPIC: "connect-offsets"
      CONNECT_STATUS_STORAGE_TOPIC: "connect-status"
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.storage.StringConverter"
      CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_REST_PORT: 8083
      CONNECT_PLUGIN_PATH: "/usr/share/java"
    ports:
      - "8083:8083"
    networks:
      - app_net
    profiles:
      - dev


  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    networks:
      - app_net
    profiles:
      - dev

volumes:
  kafka_data:
    driver: local
  pgdata:

networks:
  app_net:
